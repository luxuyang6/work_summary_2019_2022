/home/xylu/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
2021-04-14 15:56:51,888 embed: embedding.we.weight, shape=torch.Size([3747, 512]), num:1918464
2021-04-14 15:56:51,889 embed: linear.weight, shape=torch.Size([512, 2048]), num:1048576
2021-04-14 15:56:51,889 embed: linear.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,889 embed: graph_linear.weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,889 embed: graph_linear.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,889 video_enc: linear.weight, shape=torch.Size([512, 2048]), num:1048576
2021-04-14 15:56:51,889 video_enc: rnn.weight_ih_l0, shape=torch.Size([2048, 512]), num:1048576
2021-04-14 15:56:51,889 video_enc: rnn.weight_hh_l0, shape=torch.Size([2048, 512]), num:1048576
2021-04-14 15:56:51,890 video_enc: rnn.bias_ih_l0, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,890 video_enc: rnn.bias_hh_l0, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,890 video_enc: rnn.weight_ih_l0_reverse, shape=torch.Size([2048, 512]), num:1048576
2021-04-14 15:56:51,890 video_enc: rnn.weight_hh_l0_reverse, shape=torch.Size([2048, 512]), num:1048576
2021-04-14 15:56:51,890 video_enc: rnn.bias_ih_l0_reverse, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,890 video_enc: rnn.bias_hh_l0_reverse, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,890 video_enc: video_linear.weight, shape=torch.Size([512, 1024]), num:524288
2021-04-14 15:56:51,890 video_enc: video_linear.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,890 mp_encoder: ft_embed.weight, shape=torch.Size([512, 1536]), num:786432
2021-04-14 15:56:51,891 mp_encoder: ft_embed.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,891 attn_encoder: attr_order_embeds, shape=torch.Size([20, 512]), num:10240
2021-04-14 15:56:51,891 attn_encoder: first_embedding.0.weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,891 attn_encoder: first_embedding.0.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,891 attn_encoder: layers.0.loop_weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,891 attn_encoder: layers.0.weight, shape=torch.Size([6, 512, 512]), num:1572864
2021-04-14 15:56:51,891 attn_encoder: layers.1.loop_weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,891 attn_encoder: layers.1.weight, shape=torch.Size([6, 512, 512]), num:1572864
2021-04-14 15:56:51,892 attn_encoder: node_embedding.weight, shape=torch.Size([3, 512]), num:1536
2021-04-14 15:56:51,892 decoder: embedding.we.weight, shape=torch.Size([3747, 512]), num:1918464
2021-04-14 15:56:51,892 decoder: attn_lstm.weight_ih, shape=torch.Size([2048, 1536]), num:3145728
2021-04-14 15:56:51,892 decoder: attn_lstm.weight_hh, shape=torch.Size([2048, 512]), num:1048576
2021-04-14 15:56:51,892 decoder: attn_lstm.bias_ih, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,892 decoder: attn_lstm.bias_hh, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,893 decoder: lang_lstm.weight_ih, shape=torch.Size([2048, 1024]), num:2097152
2021-04-14 15:56:51,893 decoder: lang_lstm.weight_hh, shape=torch.Size([2048, 512]), num:1048576
2021-04-14 15:56:51,893 decoder: lang_lstm.bias_ih, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,893 decoder: lang_lstm.bias_hh, shape=torch.Size([2048]), num:2048
2021-04-14 15:56:51,893 decoder: attn.linear_query.weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,893 decoder: attn.linear_query.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,893 decoder: attn.attn_w.weight, shape=torch.Size([1, 512]), num:512
2021-04-14 15:56:51,893 decoder: vid_attn.linear_query.weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,893 decoder: vid_attn.linear_query.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,894 decoder: vid_attn.attn_w.weight, shape=torch.Size([1, 512]), num:512
2021-04-14 15:56:51,894 decoder: attn_linear_context.weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,894 decoder: vid_attn_linear_context.weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,894 decoder: address_layer.0.weight, shape=torch.Size([512, 1024]), num:524288
2021-04-14 15:56:51,894 decoder: address_layer.0.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,894 decoder: address_layer.2.weight, shape=torch.Size([3, 512]), num:1536
2021-04-14 15:56:51,894 decoder: address_layer.2.bias, shape=torch.Size([3]), num:3
2021-04-14 15:56:51,894 decoder: address_layer2.0.weight, shape=torch.Size([512, 1536]), num:786432
2021-04-14 15:56:51,894 decoder: address_layer2.0.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,895 decoder: address_layer2.2.weight, shape=torch.Size([4, 512]), num:2048
2021-04-14 15:56:51,895 decoder: address_layer2.2.bias, shape=torch.Size([4]), num:4
2021-04-14 15:56:51,895 decoder: memory_update_layer.0.weight, shape=torch.Size([512, 1024]), num:524288
2021-04-14 15:56:51,895 decoder: memory_update_layer.0.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,895 decoder: memory_update_layer.2.weight, shape=torch.Size([1024, 512]), num:524288
2021-04-14 15:56:51,895 decoder: memory_update_layer.2.bias, shape=torch.Size([1024]), num:1024
2021-04-14 15:56:51,895 decoder: sentinal_layer.0.weight, shape=torch.Size([512, 512]), num:262144
2021-04-14 15:56:51,895 decoder: sentinal_layer.0.bias, shape=torch.Size([512]), num:512
2021-04-14 15:56:51,895 decoder: sentinal_layer.2.weight, shape=torch.Size([1, 512]), num:512
2021-04-14 15:56:51,896 decoder: sentinal_layer.2.bias, shape=torch.Size([1]), num:1
2021-04-14 15:56:51,896 num params 59, num weights 26683400
2021-04-14 15:56:51,896 trainable: num params 42, num weights 17667080
