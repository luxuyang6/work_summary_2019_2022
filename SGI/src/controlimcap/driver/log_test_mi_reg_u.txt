embed: embedding.we.weight, shape=torch.Size([3747, 512]), num:1918464
embed: linear.weight, shape=torch.Size([512, 2048]), num:1048576
embed: linear.bias, shape=torch.Size([512]), num:512
embed: graph_linear.weight, shape=torch.Size([512, 512]), num:262144
embed: graph_linear.bias, shape=torch.Size([512]), num:512
video_enc: linear.weight, shape=torch.Size([512, 2048]), num:1048576
video_enc: rnn.weight_ih_l0, shape=torch.Size([2048, 512]), num:1048576
video_enc: rnn.weight_hh_l0, shape=torch.Size([2048, 512]), num:1048576
video_enc: rnn.bias_ih_l0, shape=torch.Size([2048]), num:2048
video_enc: rnn.bias_hh_l0, shape=torch.Size([2048]), num:2048
video_enc: rnn.weight_ih_l0_reverse, shape=torch.Size([2048, 512]), num:1048576
video_enc: rnn.weight_hh_l0_reverse, shape=torch.Size([2048, 512]), num:1048576
video_enc: rnn.bias_ih_l0_reverse, shape=torch.Size([2048]), num:2048
video_enc: rnn.bias_hh_l0_reverse, shape=torch.Size([2048]), num:2048
video_enc: video_linear.weight, shape=torch.Size([512, 1024]), num:524288
video_enc: video_linear.bias, shape=torch.Size([512]), num:512
mp_encoder: ft_embed.weight, shape=torch.Size([512, 1536]), num:786432
mp_encoder: ft_embed.bias, shape=torch.Size([512]), num:512
attn_encoder: attr_order_embeds, shape=torch.Size([20, 512]), num:10240
attn_encoder: first_embedding.0.weight, shape=torch.Size([512, 512]), num:262144
attn_encoder: first_embedding.0.bias, shape=torch.Size([512]), num:512
attn_encoder: layers.0.loop_weight, shape=torch.Size([512, 512]), num:262144
attn_encoder: layers.0.weight, shape=torch.Size([6, 512, 512]), num:1572864
attn_encoder: layers.1.loop_weight, shape=torch.Size([512, 512]), num:262144
attn_encoder: layers.1.weight, shape=torch.Size([6, 512, 512]), num:1572864
attn_encoder: node_embedding.weight, shape=torch.Size([3, 512]), num:1536
decoder: embedding.we.weight, shape=torch.Size([3747, 512]), num:1918464
decoder: attn_lstm.weight_ih, shape=torch.Size([2048, 1536]), num:3145728
decoder: attn_lstm.weight_hh, shape=torch.Size([2048, 512]), num:1048576
decoder: attn_lstm.bias_ih, shape=torch.Size([2048]), num:2048
decoder: attn_lstm.bias_hh, shape=torch.Size([2048]), num:2048
decoder: lang_lstm.weight_ih, shape=torch.Size([2048, 1024]), num:2097152
decoder: lang_lstm.weight_hh, shape=torch.Size([2048, 512]), num:1048576
decoder: lang_lstm.bias_ih, shape=torch.Size([2048]), num:2048
decoder: lang_lstm.bias_hh, shape=torch.Size([2048]), num:2048
decoder: attn.linear_query.weight, shape=torch.Size([512, 512]), num:262144
decoder: attn.linear_query.bias, shape=torch.Size([512]), num:512
decoder: attn.attn_w.weight, shape=torch.Size([1, 512]), num:512
decoder: vid_attn.linear_query.weight, shape=torch.Size([512, 512]), num:262144
decoder: vid_attn.linear_query.bias, shape=torch.Size([512]), num:512
decoder: vid_attn.attn_w.weight, shape=torch.Size([1, 512]), num:512
decoder: attn_linear_context.weight, shape=torch.Size([512, 512]), num:262144
decoder: vid_attn_linear_context.weight, shape=torch.Size([512, 512]), num:262144
decoder: address_layer.0.weight, shape=torch.Size([512, 1024]), num:524288
decoder: address_layer.0.bias, shape=torch.Size([512]), num:512
decoder: address_layer.2.weight, shape=torch.Size([3, 512]), num:1536
decoder: address_layer.2.bias, shape=torch.Size([3]), num:3
decoder: address_layer2.0.weight, shape=torch.Size([512, 1536]), num:786432
decoder: address_layer2.0.bias, shape=torch.Size([512]), num:512
decoder: address_layer2.2.weight, shape=torch.Size([4, 512]), num:2048
decoder: address_layer2.2.bias, shape=torch.Size([4]), num:4
decoder: memory_update_layer.0.weight, shape=torch.Size([512, 1024]), num:524288
decoder: memory_update_layer.0.bias, shape=torch.Size([512]), num:512
decoder: memory_update_layer.2.weight, shape=torch.Size([1024, 512]), num:524288
decoder: memory_update_layer.2.bias, shape=torch.Size([1024]), num:1024
decoder: sentinal_layer.0.weight, shape=torch.Size([512, 512]), num:262144
decoder: sentinal_layer.0.bias, shape=torch.Size([512]), num:512
decoder: sentinal_layer.2.weight, shape=torch.Size([1, 512]), num:512
decoder: sentinal_layer.2.bias, shape=torch.Size([1]), num:1
num params 59, num weights 26683400
trainable: num params 42, num weights 17667080
num_data 6811
number of resumed variables: 59
/home/xylu/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.6 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.4 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].
Threads( StanfordCoreNLP ) [02:10.38 minutes]
SPICE evaluation took: 2.415 min
loss,epoch.66.th,274.00,11.94,18.13,43.29,15.61,14.88,16.19
number of resumed variables: 59
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.7 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.2 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].
Threads( StanfordCoreNLP ) [02:13.921 minutes]
SPICE evaluation took: 2.483 min
bleu4,epoch.76.th,303.00,11.97,18.61,43.41,16.37,15.51,17.06
number of resumed variables: 59
Parsing reference captions
Parsing test captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... 
done [0.5 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.0 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.7 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.6 sec].
Threads( StanfordCoreNLP ) [01:52.649 minutes]
SPICE evaluation took: 2.114 min
cider,epoch.99.th,368.00,12.13,18.38,43.28,17.38,15.18,15.78
